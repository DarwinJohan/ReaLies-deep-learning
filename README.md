# DeepFake Detection System
## Table of Contents

Overview
Demonstration
Risks and Consequences of DeepFakes
Research Objectives
System Workflow
Data Pre-processing
Prediction Process
Model Architectures
Deployment Guide
Execution Instructions
Tools and Frameworks
Final Remarks
Contributors

## Overview

DeepFakes refer to artificially altered images or videos in which a person’s identity is digitally replaced with another individual. These manipulations are typically achieved through advanced face-swapping techniques powered by Generative Adversarial Networks (GANs). As these generative models continue to improve, distinguishing between authentic and manipulated content has become increasingly challenging.

## Risks and Consequences of DeepFakes

Can be weaponized to disseminate false information, misleading narratives, or fabricated political content.

Frequently exploited in scams and other forms of digital fraud.

May lead to psychological harm, reputational damage, and societal instability.

Media organizations, online platforms, and content distributors are actively developing countermeasures to mitigate the misuse of this technology.

## Research Objectives

Detecting DeepFake content plays a crucial role in minimizing the negative impact of malicious AI usage.

The objectives of this project include:

Developing a model capable of categorizing video content as REAL or FAKE.

Creating a detection mechanism that can be integrated into social media platforms to alert users about potentially manipulated media.

## Primary Objective:
To construct a deep learning–based framework that can identify subtle visual inconsistencies and artifacts within video frames that differentiate genuine recordings from DeepFake-generated content.

## Team :
- Darwin https://github.com/DarwinJohan
- Virly https://github.com/HinaKhina
- Kevin https://github.com/RaidToaster